{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librairie\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...\n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...\n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('data', sep=\",\", header=None)\n",
    "data.columns = ['text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a collection of emails that are not labelled. Let's try extract topics from them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ You're used to it by now... Clean up! Store the cleaned text in a new dataframe column \"clean_text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>From:  (Gary L Dare)\\nSubject: Stan Fischler, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>From:  (Cardinal Ximenez)\\nSubject: Re: The ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "      <td>From: \\nSubject: Re: Ancient Books\\nOrganizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>From:  (Cardinal Ximenez)\\nSubject: Atheists a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "      <td>From:  (Vladimir Zhivov)\\nSubject: Flames Trul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>From: jerryb@eskimo.com (Jerry Kaufman)\\nSubje...</td>\n",
       "      <td>From:  (Jerry Kaufman)\\nSubject: Re: prayers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>From: golchowy@alchemy.chem.utoronto.ca (Geral...</td>\n",
       "      <td>From:  (Gerald Olchowy)\\nSubject: Re: If You W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>From: jayne@mmalt.guild.org (Jayne Kulikauskas...</td>\n",
       "      <td>From:  (Jayne Kulikauskas)\\nSubject: quality o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>From: sclark@epas.utoronto.ca (Susan Clark)\\nS...</td>\n",
       "      <td>From:  (Susan Clark)\\nSubject: Who picks first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>From: lmvec@westminster.ac.uk (William Hargrea...</td>\n",
       "      <td>From:  (William Hargreaves)\\nSubject: Re: Help...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     From: gld@cunixb.cc.columbia.edu (Gary L Dare)...   \n",
       "1     From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "2     From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...   \n",
       "3     From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "4     From: vzhivov@superior.carleton.ca (Vladimir Z...   \n",
       "...                                                 ...   \n",
       "1194  From: jerryb@eskimo.com (Jerry Kaufman)\\nSubje...   \n",
       "1195  From: golchowy@alchemy.chem.utoronto.ca (Geral...   \n",
       "1196  From: jayne@mmalt.guild.org (Jayne Kulikauskas...   \n",
       "1197  From: sclark@epas.utoronto.ca (Susan Clark)\\nS...   \n",
       "1198  From: lmvec@westminster.ac.uk (William Hargrea...   \n",
       "\n",
       "                                             clean_text  \n",
       "0     From:  (Gary L Dare)\\nSubject: Stan Fischler, ...  \n",
       "1     From:  (Cardinal Ximenez)\\nSubject: Re: The ar...  \n",
       "2     From: \\nSubject: Re: Ancient Books\\nOrganizati...  \n",
       "3     From:  (Cardinal Ximenez)\\nSubject: Atheists a...  \n",
       "4     From:  (Vladimir Zhivov)\\nSubject: Flames Trul...  \n",
       "...                                                 ...  \n",
       "1194  From:  (Jerry Kaufman)\\nSubject: Re: prayers a...  \n",
       "1195  From:  (Gerald Olchowy)\\nSubject: Re: If You W...  \n",
       "1196  From:  (Jayne Kulikauskas)\\nSubject: quality o...  \n",
       "1197  From:  (Susan Clark)\\nSubject: Who picks first...  \n",
       "1198  From:  (William Hargreaves)\\nSubject: Re: Help...  \n",
       "\n",
       "[1199 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We start by remove e-mail adress\n",
    "def remove_mail(text):\n",
    "    \n",
    "    email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "    text_without_emails = re.sub(email_pattern, '', text)\n",
    "    return text_without_emails\n",
    "\n",
    "data['clean_text'] = data['text'].apply(remove_mail)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>from  gary l dare\\nsubject stan fischler \\nsum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>from  cardinal ximenez\\nsubject re the arrogan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "      <td>from \\nsubject re ancient books\\norganization ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>from  cardinal ximenez\\nsubject atheists and h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "      <td>from  vladimir zhivov\\nsubject flames truly br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>From: jerryb@eskimo.com (Jerry Kaufman)\\nSubje...</td>\n",
       "      <td>from  jerry kaufman\\nsubject re prayers and ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>From: golchowy@alchemy.chem.utoronto.ca (Geral...</td>\n",
       "      <td>from  gerald olchowy\\nsubject re if you were p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>From: jayne@mmalt.guild.org (Jayne Kulikauskas...</td>\n",
       "      <td>from  jayne kulikauskas\\nsubject quality of ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>From: sclark@epas.utoronto.ca (Susan Clark)\\nS...</td>\n",
       "      <td>from  susan clark\\nsubject who picks first\\nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>From: lmvec@westminster.ac.uk (William Hargrea...</td>\n",
       "      <td>from  william hargreaves\\nsubject re help\\norg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     From: gld@cunixb.cc.columbia.edu (Gary L Dare)...   \n",
       "1     From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "2     From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...   \n",
       "3     From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "4     From: vzhivov@superior.carleton.ca (Vladimir Z...   \n",
       "...                                                 ...   \n",
       "1194  From: jerryb@eskimo.com (Jerry Kaufman)\\nSubje...   \n",
       "1195  From: golchowy@alchemy.chem.utoronto.ca (Geral...   \n",
       "1196  From: jayne@mmalt.guild.org (Jayne Kulikauskas...   \n",
       "1197  From: sclark@epas.utoronto.ca (Susan Clark)\\nS...   \n",
       "1198  From: lmvec@westminster.ac.uk (William Hargrea...   \n",
       "\n",
       "                                             clean_text  \n",
       "0     from  gary l dare\\nsubject stan fischler \\nsum...  \n",
       "1     from  cardinal ximenez\\nsubject re the arrogan...  \n",
       "2     from \\nsubject re ancient books\\norganization ...  \n",
       "3     from  cardinal ximenez\\nsubject atheists and h...  \n",
       "4     from  vladimir zhivov\\nsubject flames truly br...  \n",
       "...                                                 ...  \n",
       "1194  from  jerry kaufman\\nsubject re prayers and ad...  \n",
       "1195  from  gerald olchowy\\nsubject re if you were p...  \n",
       "1196  from  jayne kulikauskas\\nsubject quality of ca...  \n",
       "1197  from  susan clark\\nsubject who picks first\\nor...  \n",
       "1198  from  william hargreaves\\nsubject re help\\norg...  \n",
       "\n",
       "[1199 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanning_text(df, column_name):\n",
    "    df['clean_text'] = df['clean_text'].str.translate(str.maketrans('','',string.punctuation))\n",
    "    df['clean_text']= df['clean_text'].str.lower()\n",
    "    df['clean_text'] = df['clean_text'].str.replace(r'\\d+','', regex=True)\n",
    "    \n",
    "cleanning_text(data,'clean_text' )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = \" \".join([word for word in word_tokens if not word in stop_words])\n",
    "    return filtered_text\n",
    "\n",
    "data['clean_text'] = data['clean_text'].apply(remove_stopwords)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "  \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lemmatized_words = \" \".join([lemmatizer.lemmatize(word) for word in word_tokens])\n",
    "    return lemmatized_words\n",
    "\n",
    "data['clean_text'] = data['clean_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Train an LDA model to extract potential topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer().fit(data['clean_text'])\n",
    "data_vectorized = vectorizer.transform(data['clean_text'])\n",
    "lda_model = LatentDirichletAllocation(n_components=3).fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize potential topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ The function to print the words associated with the potential topics is already made for you. You just have to pass the correct arguments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('chi', 3.1156675388893116), ('det', 2.4602528123836698), ('bos', 2.4074926378698027), ('cal', 2.259741459932837), ('pit', 1.9683514427461555), ('buf', 1.8196143303836076), ('tor', 1.6799844335908265), ('pitt', 1.6425889817195267), ('que', 1.513827505930599), ('howl', 1.499809133633879)]\n",
      "Topic 1:\n",
      "[('colon', 1.5840097290729214), ('testing', 1.5028500593861436), ('finalswho', 1.2958009269330877), ('statemaine', 1.2958009269215156), ('holger', 1.2762750513916064), ('finalswinner', 1.2079691957198726), ('tennessee', 1.0484661962480024), ('rfl', 1.0484661962480017), ('singapore', 1.026188873997567), ('ohlwein', 1.0202204328574698)]\n",
      "Topic 2:\n",
      "[('god', 35.97529628701285), ('game', 27.256114341175987), ('would', 26.323827070382105), ('team', 25.83993565386872), ('one', 24.438249212382697), ('line', 23.519485530952966), ('subject', 23.331137156674544), ('christian', 22.560833050126604), ('organization', 22.380166395060044), ('university', 22.22939473776321)]\n"
     ]
    }
   ],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i],topic[i])\n",
    "              for i in topic.argsort()[:-10-1:-1]])\n",
    "        \n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict topic of new text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ You can now use your LDA model to predict the topic of a new text. First, use your vectorizer to vectorize the example. Then, use your LDA model to predict the topic of the vectorized example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : 0.1009225064191745\n",
      "topic 1 : 0.10092578996849774\n",
      "topic 2 : 0.7981517036123278\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"i love play video game since i was young\"]\n",
    "new_text_vectorized = vectorizer.transform(new_text)\n",
    "lda_vectors = lda_model.transform(new_text_vectorized)\n",
    "\n",
    "print(\"topic 0 :\", lda_vectors[0][0])\n",
    "print(\"topic 1 :\", lda_vectors[0][1])\n",
    "print(\"topic 2 :\", lda_vectors[0][2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse with Azure cognitive servicesÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use cognitive services at https://azure-ml-ai900-justine-31012023.cognitiveservices.azure.com/ using key a7404d50c1384d0680f9020fee700f96\n"
     ]
    }
   ],
   "source": [
    "cog_key = 'a7404d50c1384d0680f9020fee700f96'\n",
    "cog_endpoint = 'https://azure-ml-ai900-justine-31012023.cognitiveservices.azure.com/'\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "gary l dare subject stan fischler summary devil pregame show prior hosting penguin nntppostinghost cunixbcccolumbiaedu replyto gary l dare organization phd hall line lester patrick award lunch bill torrey mentioned one option next season president miami team bob clarke working dinner clarke said worst mistake philadelphia letting mike keenan go retrospect almost player came realize keenan knew took win rumour circulating keenan back flyer nick polano sick scapegoat schedule made red wing bryan murray approved gerry meehan john muckler worried sabre prospect assistant lever say sabre get share quebec dynasty emerging mighty duck declared throw money around loosely buy team oiler coach ted green remarked guy around fill tie domis skate none fill helmet senator andrew mcbain told security guard chicago stadium warned stair leading locker room mcbain mouthed seasoned professional tumbled entire steep flight gld je souviens gary l dare go winnipeg jet go selanne domi stanley\n",
      "\n",
      "1\n",
      "cardinal ximenez subject arrogance christian organization national association disorganized line writes article mark baker writes true athiests position proof existence god much people accept church priest straight scripture proof satisfy atheist havent fully explained atheist position many theist believe proof existence god choose believe anyway havent yet found argument atheism cant quickly broken unprovable assumption isnt problem everybody need faith believe provide purely logical argument nonexistence god id really like see asking u believe blindly trying deny part u make u ask question god exist ie selfawareness reason use ability reason become ignorant animal earth god want u like right science reason prove anything however use believe faith alone since use faith one picture god eg hinduism le valid another eg christianity ahhbut use science reason faith certain belief scientific methodfor example physical law universe stable observation reality valid basis determination truth objective reality exists logical argument valid way answer question prove alan terlep scorpion say oakland university rochester mi nature\n",
      "\n",
      "2\n",
      "subject ancient book organization university kansa academic computing service line article bill mayne writes article writes former atheist converted argument excellent question ill anxious see case doubt medieval period esp thcent aquinas flourished argument useful tool everyone knew rule today cant count people knowing even basic logic seeing rhetoric good argument often indistinguishable poor one last sentence ironic since many reader socreligionchristian seem embarrassed apologist josh mcdowell c lewis havent followed whatever discussion may people feel c lewis excellent apologist see reason embarrassment think error flawed argument reason dismissing thinker must dismiss nearly every thinker descartes kant philosophy course introduce weakness also express rather odd sense history make think mass aquinas day mostly illiterate knew rhetoric logic people today writing period seem elevated consider cream crop speak could read write everyone medieval period knew rule matter uncritically accepting told said nothing mass however comparing mass day aquinas day really odd read ortega gasset im talking familiar experience arguing night winning logic evidence discover opponent unaware even intuitively thing like entailment let alone pragmatic assuming party college graduate better dont bother ken nobody explain everything everybody opinion g k chesterton\n",
      "\n",
      "3\n",
      "cardinal ximenez subject atheist hell organization national association disorganized line hello seen two common thread running posting atheist newsgroup think used explain unfortunately dont direct quote handy atheist believe die die forever god would condemn fail believe eternal death unfair dont see problem christian hell definition eternal deathexactly atheist expecting die there reason hell especially awfulto people eternal death bad enough literal interpreter bible problem view since bible talk fire hell personally dont think people hell thrust flame expect jesus doubleedged sword issuing mouthi treat statement metaphorical alan terlep scorpion say oakland university rochester mi nature rushing angel fear tread jody\n",
      "\n",
      "4\n",
      "vladimir zhivov subject flame truly brutal loss organization carleton university line subject suggests flame impressive afternoon dropping decision la king flame neglected show especially zone king hit least five post flame best line probably skrudlandpaslawskiberube tell bad flame gary suter scored great goal fact three flame goal scored dmen yawney dahlquist getting others also made bonehead play king pat conacher especially impressive game chippy dan mirouelli lost control early never recovered highsticks crosscheck punch hit behind fleury got game misconduct rubbing warren rychel behind flame dominated game physically failed take advantage due horrendous defensive lapse dont think vernon blamed goal calgary went dmen roger johansson played lw looked lost imho hope king insert chris lindbergh paul kruse sergei makarov wednesday game gretzky left game nd period charleyhorse idea serious didnt return still think flame win series better buckle vlad impaler\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a collection of reviews with dataframe\n",
    "reviews = []\n",
    "for i in range(5):\n",
    "    review = {\"id\": i, \"text\": data['clean_text'][i]}\n",
    "    reviews.append(review)\n",
    "    \n",
    "\n",
    "for review_num in range(len(reviews)):\n",
    "    # print the review text\n",
    "     print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " - Language: English\n",
      " - Code: en\n",
      " - Score: 0.9864864945411682\n",
      "\n",
      "1\n",
      " - Language: English\n",
      " - Code: en\n",
      " - Score: 1.0\n",
      "\n",
      "2\n",
      " - Language: English\n",
      " - Code: en\n",
      " - Score: 1.0\n",
      "\n",
      "3\n",
      " - Language: English\n",
      " - Code: en\n",
      " - Score: 1.0\n",
      "\n",
      "4\n",
      " - Language: English\n",
      " - Code: en\n",
      " - Score: 0.9785714149475098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a client for your text analytics cognitive service resource\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
    "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Analyze the reviews you read from the /data/reviews folder earlier\n",
    "language_analysis = text_analytics_client.detect_language(documents=reviews)\n",
    "\n",
    "# print detected language details for each review\n",
    "for review_num in range(len(reviews)):\n",
    "    # print the review id\n",
    "    print(reviews[review_num]['id'])\n",
    "\n",
    "    # Get the language details for this review\n",
    "    lang = language_analysis.documents[review_num].detected_languages[0]\n",
    "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\n",
    "\n",
    "    # Add the detected language code to the collection of reviews (so we can do further analysis)\n",
    "    reviews[review_num][\"language\"] = lang.iso6391_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Key Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "Key Phrases:\n",
      "\t mike keenan\n",
      "\t cunixbcccolumbiaedu replyto gary\n",
      "\t dinner clarke\n",
      "\t season president miami team bob clarke\n",
      "\t helmet senator andrew mcbain\n",
      "\t stair leading locker room mcbain\n",
      "\t dare organization phd hall line lester patrick award lunch bill torrey\n",
      "\t team oiler coach ted green remarked guy\n",
      "\t red wing bryan murray approved gerry meehan john muckler worried sabre prospect assistant lever\n",
      "\t security guard chicago stadium\n",
      "\t seasoned professional tumbled entire steep flight gld je\n",
      "\t prior hosting penguin\n",
      "\t flyer nick polano sick scapegoat schedule\n",
      "\t option\n",
      "\t tie domis skate\n",
      "\t share quebec dynasty\n",
      "\t subject stan fischler summary devil pregame\n",
      "\t worst mistake philadelphia\n",
      "\t throw money\n",
      "\t mighty duck\n",
      "\t winnipeg jet\n",
      "\t retrospect\n",
      "\t win rumour\n",
      "\t player\n",
      "\t selanne domi stanley\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "Key Phrases:\n",
      "\t question god\n",
      "\t use faith\n",
      "\t picture god\n",
      "\t logical argument nonexistence god id\n",
      "\t ability reason\n",
      "\t selfawareness reason\n",
      "\t true athiests position proof existence god\n",
      "\t right science reason\n",
      "\t ignorant animal earth god\n",
      "\t logical argument valid way answer question\n",
      "\t atheist havent\n",
      "\t argument atheism\n",
      "\t christianity ahhbut use science reason faith certain belief scientific methodfor example physical law universe stable observation reality valid basis determination truth objective reality\n",
      "\t church priest straight scripture proof\n",
      "\t cardinal ximenez subject arrogance christian organization national association disorganized line writes article mark baker\n",
      "\t alan terlep scorpion\n",
      "\t people\n",
      "\t hinduism\n",
      "\t oakland university rochester mi nature\n",
      "\t unprovable assumption isnt problem\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "Key Phrases:\n",
      "\t mass day aquinas day\n",
      "\t think mass aquinas day\n",
      "\t rhetoric logic people\n",
      "\t argument excellent question\n",
      "\t rhetoric good argument\n",
      "\t c lewis excellent apologist\n",
      "\t error flawed argument reason\n",
      "\t basic logic\n",
      "\t count people\n",
      "\t medieval period esp thcent aquinas flourished argument useful tool\n",
      "\t reason embarrassment\n",
      "\t night winning logic evidence\n",
      "\t rule matter\n",
      "\t embarrassed apologist josh mcdowell c lewis havent\n",
      "\t odd read ortega gasset im\n",
      "\t odd sense history\n",
      "\t thinker descartes kant philosophy course\n",
      "\t subject ancient book organization university kansa academic computing service line article bill mayne\n",
      "\t familiar experience\n",
      "\t case\n",
      "\t weakness\n",
      "\t discussion\n",
      "\t pragmatic assuming party college graduate better dont\n",
      "\t reader socreligionchristian\n",
      "\t ken\n",
      "\t entailment\n",
      "\t atheist\n",
      "\t thing\n",
      "\t sentence ironic\n",
      "\t cream crop\n",
      "\t opinion g\n",
      "\t chesterton\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "Key Phrases:\n",
      "\t reason hell\n",
      "\t die\n",
      "\t problem christian hell definition eternal deathexactly atheist\n",
      "\t people hell thrust flame\n",
      "\t eternal death unfair dont\n",
      "\t dont direct quote handy atheist\n",
      "\t posting atheist newsgroup\n",
      "\t awfulto people eternal death bad\n",
      "\t cardinal ximenez subject atheist hell organization national association disorganized line hello\n",
      "\t literal interpreter bible problem view\n",
      "\t oakland university rochester mi nature\n",
      "\t statement metaphorical alan terlep scorpion\n",
      "\t mouthi\n",
      "\t jesus doubleedged sword\n",
      "\t common thread\n",
      "\t angel fear tread jody\n",
      "\t fail\n",
      "\t god\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "Key Phrases:\n",
      "\t king flame\n",
      "\t flame goal\n",
      "\t game gretzky\n",
      "\t game misconduct\n",
      "\t post flame best line\n",
      "\t vladimir zhivov subject flame\n",
      "\t bad flame gary suter\n",
      "\t zone king\n",
      "\t impressive game chippy dan mirouelli\n",
      "\t lost imho hope king\n",
      "\t great goal fact\n",
      "\t bonehead play king pat conacher\n",
      "\t game nd period charleyhorse idea serious didnt\n",
      "\t vernon blamed goal calgary\n",
      "\t impressive afternoon\n",
      "\t dmen roger johansson\n",
      "\t dmen yawney dahlquist\n",
      "\t brutal loss organization carleton university line subject\n",
      "\t chris lindbergh paul kruse sergei makarov\n",
      "\t horrendous defensive lapse dont\n",
      "\t control\n",
      "\t lw\n",
      "\t skrudlandpaslawskiberube\n",
      "\t advantage\n",
      "\t warren rychel\n",
      "\t highsticks crosscheck punch\n",
      "\t series better buckle vlad impaler\n",
      "\t decision\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the client and reviews you created in the previous code cell to get key phrases\n",
    "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\n",
    "\n",
    "# print key phrases for each review\n",
    "for review_num in range(len(reviews)):\n",
    "    # print the review id\n",
    "    print(reviews[review_num]['id'])\n",
    "\n",
    "    # Get the key phrases in this review\n",
    "    print('\\nKey Phrases:')\n",
    "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\n",
    "    # Print each key phrase\n",
    "    for key_phrase in key_phrases:\n",
    "        print('\\t', key_phrase)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : positive (0.9802271127700806)\n",
      "1 : positive (0.9999222755432129)\n",
      "2 : negative (0.13061869144439697)\n",
      "3 : negative (0.0009417235851287842)\n",
      "4 : negative (0.00018808245658874512)\n"
     ]
    }
   ],
   "source": [
    "# Use the client and reviews you created previously to get sentiment scores\n",
    "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\n",
    "\n",
    "# Print the results for each review\n",
    "for review_num in range(len(reviews)):\n",
    "\n",
    "    # Get the sentiment score for this review\n",
    "    sentiment_score = sentiment_analysis.documents[review_num].score\n",
    "\n",
    "    # classifiy 'positive' if more than 0.5, \n",
    "    if sentiment_score < 0.5:\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'positive'\n",
    "\n",
    "    # print file name and sentiment\n",
    "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
