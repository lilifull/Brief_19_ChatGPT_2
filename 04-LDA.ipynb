{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librairie\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...\n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...\n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('data', sep=\",\", header=None)\n",
    "data.columns = ['text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a collection of emails that are not labelled. Let's try extract topics from them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ You're used to it by now... Clean up! Store the cleaned text in a new dataframe column \"clean_text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove ponctuation \n",
    "data[\"clean_text\"] = data['text'].str.translate(str.maketrans('','',string.punctuation))\n",
    "#remove upper case\n",
    "data['clean_text']=data['clean_text'].str.lower()\n",
    "#remove numbers\n",
    "data['clean_text'] = data['clean_text'].str.replace(r'\\d+','', regex=True)\n",
    "#remove stop words\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = \" \".join([word for word in word_tokens if not word in stop_words])\n",
    "    return filtered_text\n",
    "\n",
    "data['clean_text'] = data['clean_text'].apply(remove_stopwords)\n",
    "#lemmatize\n",
    "def lemmatize_text(text):\n",
    "  \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lemmatized_words = \" \".join([lemmatizer.lemmatize(word) for word in word_tokens])\n",
    "    return lemmatized_words\n",
    "\n",
    "data['clean_text'] = data['clean_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>gldcunixbcccolumbiaedu gary l dare subject sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>atterlepvelaacsoaklandedu cardinal ximenez sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "      <td>minerkuhubccukansedu subject ancient book orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>atterlepvelaacsoaklandedu cardinal ximenez sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "      <td>vzhivovsuperiorcarletonca vladimir zhivov subj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>From: jerryb@eskimo.com (Jerry Kaufman)\\nSubje...</td>\n",
       "      <td>jerrybeskimocom jerry kaufman subject prayer a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>From: golchowy@alchemy.chem.utoronto.ca (Geral...</td>\n",
       "      <td>golchowyalchemychemutorontoca gerald olchowy s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>From: jayne@mmalt.guild.org (Jayne Kulikauskas...</td>\n",
       "      <td>jaynemmaltguildorg jayne kulikauskas subject q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>From: sclark@epas.utoronto.ca (Susan Clark)\\nS...</td>\n",
       "      <td>sclarkepasutorontoca susan clark subject pick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>From: lmvec@westminster.ac.uk (William Hargrea...</td>\n",
       "      <td>lmvecwestminsteracuk william hargreaves subjec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     From: gld@cunixb.cc.columbia.edu (Gary L Dare)...   \n",
       "1     From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "2     From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...   \n",
       "3     From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "4     From: vzhivov@superior.carleton.ca (Vladimir Z...   \n",
       "...                                                 ...   \n",
       "1194  From: jerryb@eskimo.com (Jerry Kaufman)\\nSubje...   \n",
       "1195  From: golchowy@alchemy.chem.utoronto.ca (Geral...   \n",
       "1196  From: jayne@mmalt.guild.org (Jayne Kulikauskas...   \n",
       "1197  From: sclark@epas.utoronto.ca (Susan Clark)\\nS...   \n",
       "1198  From: lmvec@westminster.ac.uk (William Hargrea...   \n",
       "\n",
       "                                             clean_text  \n",
       "0     gldcunixbcccolumbiaedu gary l dare subject sta...  \n",
       "1     atterlepvelaacsoaklandedu cardinal ximenez sub...  \n",
       "2     minerkuhubccukansedu subject ancient book orga...  \n",
       "3     atterlepvelaacsoaklandedu cardinal ximenez sub...  \n",
       "4     vzhivovsuperiorcarletonca vladimir zhivov subj...  \n",
       "...                                                 ...  \n",
       "1194  jerrybeskimocom jerry kaufman subject prayer a...  \n",
       "1195  golchowyalchemychemutorontoca gerald olchowy s...  \n",
       "1196  jaynemmaltguildorg jayne kulikauskas subject q...  \n",
       "1197  sclarkepasutorontoca susan clark subject pick ...  \n",
       "1198  lmvecwestminsteracuk william hargreaves subjec...  \n",
       "\n",
       "[1199 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Train an LDA model to extract potential topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer().fit(data['clean_text'])\n",
    "data_vectorized = vectorizer.transform(data['clean_text'])\n",
    "lda_model = LatentDirichletAllocation(n_components=2).fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize potential topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ The function to print the words associated with the potential topics is already made for you. You just have to pass the correct arguments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('chi', 2.6685094495086075), ('det', 2.0674976863375814), ('bos', 1.919179264652361), ('pit', 1.8939816719292795), ('buf', 1.6899258831579502), ('cal', 1.638765576776278), ('tor', 1.5347142518262127), ('que', 1.4389783971997983), ('mtl', 1.3937268987685103), ('phi', 1.3898478751231562)]\n",
      "Topic 1:\n",
      "[('god', 35.57194016445812), ('game', 26.72206700935704), ('would', 25.95737534746873), ('team', 25.45007461494964), ('one', 24.15667959549748), ('line', 22.907337896952814), ('subject', 22.71345239589592), ('christian', 22.33605603202051), ('organization', 21.805878830091654), ('university', 21.68758293574393)]\n"
     ]
    }
   ],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i],topic[i])\n",
    "              for i in topic.argsort()[:-10-1:-1]])\n",
    "        \n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict topic of new text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ You can now use your LDA model to predict the topic of a new text. First, use your vectorizer to vectorize the example. Then, use your LDA model to predict the topic of the vectorized example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : 0.15537712719337737\n",
      "topic 1 : 0.8446228728066226\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"i love play video game since i was young\"]\n",
    "new_text_vectorized = vectorizer.transform(new_text)\n",
    "lda_vectors = lda_model.transform(new_text_vectorized)\n",
    "\n",
    "print(\"topic 0 :\", lda_vectors[0][0])\n",
    "print(\"topic 1 :\", lda_vectors[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
